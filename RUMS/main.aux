\relax 
\@writefile{toc}{\contentsline {section}{\numberline {1}Intoroduction}{1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Fundermetal concepts of Machine Learning}{1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}教師あり機械学習の具体例}{2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}単回帰分析・重回帰分析}{2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}線形回帰}{3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}過学習と正則化}{4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces $d = 4$の時の多項式回帰の過学習}}{5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces $\lambda = 700$, $d = 4$の時のLasso正則化多項式回帰}}{6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces $\alpha = 30000$, $d = 4$の時のLasso正則化多項式回帰の未学習}}{6}\protected@file@percent }
\bibcite{GAN}{1}
\bibcite{SGAN}{2}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}ロジスティック回帰と勾配降下法}{7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Deep Learning}{7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Neural Network}{7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}The Universal Theorem of Neural Network}{7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Generative Adversarial Networks}{7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}GANの定式化}{7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Applications of GANs}{7}\protected@file@percent }
