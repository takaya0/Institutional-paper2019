\documentclass[11pt, a4paper, dvipdfmx]{jsarticle}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage[psamsfonts]{amssymb}
\usepackage{color}
\usepackage{ascmac}
\usepackage{amsfonts}
\usepackage{mathrsfs}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{fancybox}
\usepackage{enumerate}
\usepackage{verbatim}
\usepackage{subfigure}
\usepackage{proof}
\usepackage{listings}
\usepackage{otf}

\theoremstyle{definition}

%
%%%%%%%%%%%%%%%%%%%%%%
%ここにないパッケージを入れる人は，必ずここに記載すること.
%
%%%%%%%%%%%%%%%%%%%%%%
%ここからはコード表です.
%

\def\inner<#1>{\langle #1 \rangle}

%%%%%%%%%%%%%%%%%%%%

\newtheorem*{Axiom*}{公理}
\newtheorem*{Definition*}{定義}
\newtheorem*{Theorem*}{Theorem}
\newtheorem*{Proposition*}{命題}
\newtheorem*{Lemma*}{補題}
\newtheorem*{Example*}{例}
\newtheorem*{Corollary*}{系}
\newtheorem*{Claim*}{主張}
\newtheorem*{Property*}{性質}
\newtheorem*{Attention*}{注意}
\newtheorem*{Question*}{問}
\newtheorem*{Problem*}{問題}
\newtheorem*{Consideration*}{考察}
\newtheorem*{Alert*}{警告}
\renewcommand{\proofname}{\bfseries Proof}

%%%%%%%%%%%%%%%%%%%%%%
%%

\newcommand{\A}{\bf 証明}
\newcommand{\B}{\it Proof}

%英語で定義や定理を書きたい場合こっちのコードを使うこと.

\newtheorem{Axiom+}{Axiom}[section]
\newtheorem{Definition+}[Axiom+]{Definition}
\newtheorem{Theorem+}[Axiom+]{Theorem}
\newtheorem{Proposition+}[Axiom+]{Proposition}
\newtheorem{Lemma+}[Axiom+]{Lemma}
\newtheorem{Example+}[Axiom+]{Example}
\newtheorem{Corollary+}[Axiom+]{Corollary}
\newtheorem{Claim+}[Axiom+]{Claim}
\newtheorem{Property+}[Axiom+]{Property}
\newtheorem{Attention+}[Axiom+]{Attention}
\newtheorem{Question+}[Axiom+]{Question}
\newtheorem{Problem+}[Axiom+]{Problem}
\newtheorem{Consideration+}[Axiom+]{Consideration}
\newtheorem{Alert+}{Alert}

%commmand

\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\W}{{\cal W}}
\newcommand{\cS}{{\cal S}}
\newcommand{\Wpm}{W^{\pm}}
\newcommand{\Wp}{W^{+}}
\newcommand{\Wm}{W^{-}}
\newcommand{\p}{\partial}
\newcommand{\Dx}{D_{x}}
\newcommand{\Dxi}{D_{\xi}}
\newcommand{\lan}{\langle}
\newcommand{\ran}{\rangle}
\newcommand{\pal}{\parallel}
\newcommand{\dip}{\displaystyle}
\newcommand{\e}{\varepsilon}
\newcommand{\dl}{\delta}
\newcommand{\pphi}{\varphi}
\newcommand{\ti}{\tilde}
\newcommand{\X}{\mathcal{X}}
\newcommand{\Y}{\mathcal{Y}}
\newcommand{\K}{\mathbb{K}}
\newcommand{\normedsp}{(V, \|\cdot\|)}
\newcommand{\innersp}{(V, \inner<\cdot, \cdot>)}

\title{Universal Approximation Theorem of Neural Network}
\author{数理科学科 3回生 小泉 孝弥}
\date{}
\begin{document}
\maketitle
\begin{abstract}
    機械学習という単語を一言で説明するならば, 「関数近似器」である.
    今回のReMakersの機関紙では機械学習および第3次人工知能ブームの火付け役となった
    「深層学習」を数学的に定義し, 深層学習の中心となる「ニューラルネットワーク」が万能関数近似器であることを示す.
    なお, 本機関紙の前提知識は数学科3回生レベルの数学である.
\end{abstract}
\section{人工知能・AIについて}
現在, 人工知能(Artificial Intelligence)の厳密な定義は完成しておらず, 専門家の中でも意見が分かれている。
なので、この機関紙では人工知能の定義について触れることはせず、現在の, 人工知能の中心技術である「機械学習」について
説明する.
\subsection{機械学習・深層学習}
最初に述べたとおり, 機械学習(Machine Learning)とは関数近似器である. 
もう少し詳細に述べれば, 入力空間と呼ばれる集合$\X$から出力空間と呼ばれる集合への良い写像$f:\X\to\Y$
を構成するのが機械学習である.　機械学習は主に, 株価などのあるものの値を予想するモデルである「回帰(Regression)」, 
あるものがどのクラスに属しているかを予測するモデルである「分類(Classify)」の2つに分けられる. 機械学習の中でも特に, あとで定義する, ニューラルネットワークと
いうものを用いる学習手法を深層学習(Deep Learning)という.
\subsection{深層学習と万能近似性}
深層学習は以下の定理から万能関数近似器と呼ばれている. 
\begin{Theorem*}(万能関数近似定理)\\
    $X$を集合とし$f:X\to\R$を性質の良い関数とする. この時, $f$を
    任意の精度で近似できるようなニューラルネットワークが存在する.
\end{Theorem*}
今回の機関紙の目標はこの定理を証明することであるが, 今のままでは曖昧な単語が多すぎるため, 数学の問題として
扱うことができない. したがって, 今からこの定理を数学的に述べなければならない. しかしながら, 流れの都合上
この定理を数学的に述べる前に, この定理の証明に不可欠な「ハーン・バナッハの拡張定理」と「リースの表現定理」
を証明することにする.
\section{関数解析の基礎}
リースの表現定理およびハーンバナッハの拡張定理は共に関数解析学(Functional Analysis)
と呼ばれる分野の定理である. したがって, この節では関数解析学の基礎事項を説明する. なお, ベクトル空間の
係数体は実数体または複素数体とし, $\K$で表記する.
\subsection{関数解析の基礎空間}
\begin{Definition+}(ノルム空間)\\
    $V$をベクトル空間とする. 写像$\|\cdot\|:V\to\R$が以下の性質を満たすとする.
    \begin{enumerate}
        \item $\forall v\in V, \|v\| \geq 0$,
        \item $\forall v\in V, \|v\| = 0 \iff v = 0$,
        \item $\forall \alpha\in\K, \forall v\in V, \|\alpha v\| = |\alpha|\|v\|$ and 
        \item $\forall v, w\in V, \|v + w\|\leq \|v\| + \|w\|$.
    \end{enumerate}
    この時, $\|\cdot\|$を$V$のノルムといい, $(V, \|\cdot\|)$をノルム空間(normed space)という.
\end{Definition+}
\begin{Proposition+}
    $\normedsp$をノルム空間とする. この時, 以下で定義される写像$d:V\times V\to\R$は$V$上の距離となる.
    \begin{align*}
        d(x, y) = \|x - y\|.
    \end{align*}
    この距離を, ノルムから入る距離と呼ぶ.
    \begin{proof}
        ノルムの定義より明らかである.
    \end{proof}
\end{Proposition+}
この定理より, ノルム空間はノルムから入る距離によって距離空間となる. 次にバナッハ空間を定義していく.
\begin{Definition+}(完備)\\
    $(X, d)$を距離空間とする. $X$の任意のコーシー列$\{x_{n}\}_{n\in\N}$が収束する時
    , $(X, d)$を完備距離空間(complete metric space)または単に, 完備(complete)という.
\end{Definition+}

\begin{Definition+}(バナッハ空間)\\
    ノルム空間が距離空間として完備である時, バナッハ空間(Banach space)という.
\end{Definition+}
次にヒルベルト空間を定義する.
\begin{Definition+}(内積空間)\\
    $V$をベクトル空間とする. $\inner<\cdot, \cdot>: V\times V\to\K$が以下の性質を満たすとする.
    \begin{enumerate}
        \item $\forall v\in V, \inner<v, v>\geq 0$,
        \item $\forall v\in V, \inner<v, v> = 0\iff v = 0$,
        \item $\forall v, w\in V, \inner<v, w> = \overline{\inner<w, v>}$,
        \item $\forall u, v, w\in V, \inner<u + v, w> = \inner<u, w> + \inner<v, w>$ and
        \item $\forall v, w\in V, \forall\alpha\in\K, \inner<\alpha v, w> = \alpha\inner<v, w>$.
    \end{enumerate}
    との時$\inner<\cdot, \cdot>$を$V$の内積(inner)といい, 組$(V, \inner<\cdot, \cdot>)$を内積空間(inner space)という.
\end{Definition+}
\begin{Proposition+}
    $\innersp$を内積空間とする. この時, 以下で定義される写像$\|\cdot\|:V\to\R$はノルムとなる.
    \begin{align*}
        \|x\| = \sqrt{\inner<x, x>}.
    \end{align*}
    \begin{proof}
        内積の定義より明らか.
    \end{proof}
\end{Proposition+}
これにより, 内積空間はノルム空間となる.
\begin{Definition+}(ヒルベルト空間)\\
    内積空間がバナッハ空間であるとき, ヒルベルト空間(Hilbert space)という.
\end{Definition+}
\subsection{有界線形作用素}
\begin{Definition+}(線形作用素)\\
    $V$, $W$をベクトル空間とし$f:V\to W$が
    \begin{enumerate}
        \item $\forall v, w\in V, f(v + w) = f(v) + f(w)$,
        \item $\forall\alpha\in\K, f(\alpha v) = \alpha f(v)$.
    \end{enumerate}
    を満たす時, $f$を線形作用素(linear operator)という.
\end{Definition+}

\begin{Definition+}(有界)\\
    $(V_{1}, \|\cdot\|_{1})$, $(V_{2}, \|\cdot\|_{2})$をノルム空間とし$f$を$V_{1}$から$V_{2}$への写像とする.
    $f$が,
    \begin{align*}
        \exists c\geq 0\text{ s.t. }\forall x\in V_{1}, \|f(x)\|_{2}\leq c\|x\|_{1}
    \end{align*}
    を満たす時, $f$は有界(bounded)であるという.
\end{Definition+}

\begin{Definition+}(有界線形作用素)\\
    有界であり線形である写像を有界線形作用素(bounded linear operator)という.
\end{Definition+}
\newpage
\begin{Theorem+}
    $(V_{1}, \|\cdot\|_{1})$, $(V_2. \|\cdot\|_{2})$をノルム空間とし, $T:V_1\to V_2$を有界線形作用素とする.　
    また集合$C$を以下で定義する.
    \begin{align*}
        C = \{c\geq 0~|~\forall x\in V_{1}, \|f(x)\|_{2}\leq c\|x\|_{1}\}.
    \end{align*}
    この時, 以下のことが成立する.
\end{Theorem+}

\begin{thebibliography}{9}
    \bibitem{neural} https://tutorials.chainer.org/ja/index.html
    \bibitem{ML} https://github.com/Runnrairu/machinelearning\verb|_|text
    \bibitem{kernel} カーネル法入門―正定値カーネルによるデータ解析・福水健次・2010
    \bibitem{ML1} 統計的学習理論・金森 敬文・2015
    \bibitem{functional} 函数解析 POD版・前田 周一郎・2007
\end{thebibliography}
\end{document}
